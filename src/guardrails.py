import re

# ====================== INBOUND CHECK ====================== #
def inbound_check(query: str):
    """
    Runs BEFORE sending query to router/LLM.
    Validates, sanitizes, and blocks harmful or strongly off-topic input.
    """

    q = query.lower().strip()

    # 0. Allow greetings
    if q in greetings() or q.startswith(tuple(greetings())):
        return {"status": "ok", "cleaned_query": query}

    # 1. Allow follow-up questions
    if any(key in q for key in followup_keywords()):
        return {"status": "ok", "cleaned_query": query}

    # 2. Block harmful categories
    if detect_harmful_intent(query):
        return {"status": "blocked", "message": "I can't help with that."}

    # 3. Block jailbreak attempts
    if detect_jailbreak(query):
        return {"status": "blocked", "message": "Request denied for safety reasons."}

    # 4. Block strong off-topic content
    if any(key in q for key in off_topic_keywords()):
        return {
            "status": "blocked",
            "message": "I can only answer questions related to company annual reports and financial information."
        }

    # 5. Mask PII (safe to always allow)
    cleaned = mask_pii(query)

    return {"status": "ok", "cleaned_query": cleaned}



# ====================== OUTBOUND CHECK ====================== #
def outbound_check(response: str):
    """
    Runs AFTER LLM finishes but BEFORE sending output to the user.
    """

    # prevent revealing system instructions
    if "system prompt" in response.lower() and "gpt" in response.lower():
        return "[Output filtered by safety policy]"

    # mask any PII generated by mistake
    response = mask_pii(response)

    return response



# ====================== UTILITIES ====================== #
def off_topic_keywords():
    return [
        "recipe", "cook", "cooking", "biryani", "chicken", "pizza",
        "buy", "shopping", "cheapest", "amazon", "flipkart",
        "travel", "flight", "hotel",
        "doctor", "medicine", "health",
        "gym", "workout",
        "python code", "write code", "script", "bug", "program",
        "movie", "netflix", "song", "music",
        "love", "relationship", "dating"
    ]

def followup_keywords():
    return [
        "previous message", "last answer", "repeat", "continue",
        "explain that", "explain more", "summarize", "what did i ask",
        "what did you say"
    ]

def greetings():
    return ["hi", "hello", "hey", "thanks", "ok"]

def detect_harmful_intent(text: str):
    harmful_keywords = [
        "kill myself", "harm", "make a bomb", "hack", "steal",
        "ddos", "suicide", "drug", "weapon"
    ]
    t = text.lower()
    return any(k in t for k in harmful_keywords)


def detect_jailbreak(text: str):
    jailbreak_triggers = [
        "ignore previous instructions",
        "pretend to be",
        "act as dan",
        "reveal your system prompt",
        "bypass",
        "jailbreak"
    ]
    t = text.lower()
    return any(k in t for k in jailbreak_triggers)


def mask_pii(text: str):
    # Mask phone numbers
    text = re.sub(r"\b\d{10}\b", "[PHONE_REDACTED]", text)
    # Mask email addresses
    text = re.sub(r"[A-Za-z0-9._%+-]+@[A-Za-z.-]+\.[A-Za-z]{2,}", "[EMAIL_REDACTED]", text)
    return text
